{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acKJ071_Puky"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_05_2_kfold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpq_LplMPukz"
      },
      "source": [
        "# T81-558: Applications of Deep Neural Networks\n",
        "**Module 5: Regularization and Dropout**\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdaBK7iZPukz"
      },
      "source": [
        "# Module 5 Material\n",
        "\n",
        "* Part 5.1: Part 5.1: Introduction to Regularization: Ridge and Lasso [[Video]](https://www.youtube.com/watch?v=jfgRtCYjoBs&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_05_1_reg_ridge_lasso.ipynb)\n",
        "* **Part 5.2: Using K-Fold Cross Validation with Keras** [[Video]](https://www.youtube.com/watch?v=maiQf8ray_s&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_05_2_kfold.ipynb)\n",
        "* Part 5.3: Using L1 and L2 Regularization with Keras to Decrease Overfitting [[Video]](https://www.youtube.com/watch?v=JEWzWv1fBFQ&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_05_3_keras_l1_l2.ipynb)\n",
        "* Part 5.4: Drop Out for Keras to Decrease Overfitting [[Video]](https://www.youtube.com/watch?v=bRyOi0L6Rs8&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_05_4_dropout.ipynb)\n",
        "* Part 5.5: Benchmarking Keras Deep Learning Regularization Techniques [[Video]](https://www.youtube.com/watch?v=1NLBwPumUAs&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_05_5_bootstrap.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItTstIfAPuk0"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "The following code ensures that Google CoLab is running and maps Google Drive if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCcFhf4xPuk0",
        "outputId": "fc760623-911f-44bc-833c-89320e51cf4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: using Google CoLab\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0omIZz-Puk1"
      },
      "source": [
        "# Part 5.2: Using K-Fold Cross-validation with PyTorch\n",
        "\n",
        "You can use cross-validation for a variety of purposes in predictive modeling:\n",
        "\n",
        "* Generating out-of-sample predictions from a neural network\n",
        "* Estimate a good number of epochs to train a neural network for (early stopping)\n",
        "* Evaluate the effectiveness of certain hyperparameters, such as activation functions, neuron counts, and layer counts\n",
        "\n",
        "Cross-validation uses several folds and multiple models to provide each data segment a chance to serve as both the validation and training set. Figure 5.CROSS shows cross-validation.\n",
        "\n",
        "**Figure 5.CROSS: K-Fold Crossvalidation**\n",
        "![K-Fold Crossvalidation](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_1_kfold.png \"K-Fold Crossvalidation\")\n",
        "\n",
        "It is important to note that each fold will have one model (neural network). To generate predictions for new data (not present in the training set), predictions from the fold models can be handled in several ways:\n",
        "\n",
        "* Choose the model with the highest validation score as the final model.\n",
        "* Preset new data to the five models (one for each fold) and average the result (this is an [ensemble](https://en.wikipedia.org/wiki/Ensemble_learning)).\n",
        "* Retrain a new model (using the same settings as the cross-validation) on the entire dataset. Train for as many epochs and with the same hidden layer structure.\n",
        "\n",
        "Generally, I prefer the last approach and will retrain a model on the entire data set once I have selected hyper-parameters. Of course, I will always set aside a final holdout set for model validation that I do not use in any aspect of the training process.\n",
        "\n",
        "## Regression vs Classification K-Fold Cross-Validation\n",
        "\n",
        "Regression and classification are handled somewhat differently concerning cross-validation. Regression is the simpler case where you can break up the data set into K folds with little regard for where each item lands. For regression, the data items should fall into the folds as randomly as possible. It is also important to remember that not every fold will necessarily have the same number of data items. It is not always possible for the data set to be evenly divided into K folds. For regression cross-validation, we will use the Scikit-Learn class **KFold**.\n",
        "\n",
        "Cross-validation for classification could also use the **KFold** object; however, this technique would not ensure that the class balance remains the same in each fold as in the original. The balance of classes that a model was trained on must remain the same (or similar) to the training set. Drift in this distribution is one of the most important things to monitor after a trained model has been placed into actual use. Because of this, we want to make sure that the cross-validation itself does not introduce an unintended shift. This technique is called stratified sampling and is accomplished by using the Scikit-Learn object **StratifiedKFold** in place of **KFold** whenever you use classification. In summary, you should use the following two objects in Scikit-Learn:\n",
        "\n",
        "* **KFold** When dealing with a regression problem.\n",
        "* **StratifiedKFold** When dealing with a classification problem.\n",
        "\n",
        "The following two sections demonstrate cross-validation with classification and regression. \n",
        "\n",
        "## Out-of-Sample Regression Predictions with K-Fold Cross-Validation\n",
        "\n",
        "The following code trains the simple dataset using a 5-fold cross-validation. The expected performance of a neural network of the type trained here would be the score for the generated out-of-sample predictions. We begin by preparing a feature vector using the **jh-simple-dataset** to predict age. This model is set up as a regression problem."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROBuFzoMcg6S",
        "outputId": "96b8afa7-3c40-4ddf-8efb-8ecae691a4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import copy\n",
        "\n",
        "class EarlyStopping():\n",
        "  def __init__(self, patience=5, min_delta=0, restore_best_weights=True):\n",
        "    self.patience = patience\n",
        "    self.min_delta = min_delta\n",
        "    self.restore_best_weights = restore_best_weights\n",
        "    self.best_model = None\n",
        "    self.best_loss = None\n",
        "    self.counter = 0\n",
        "    self.status = \"\"\n",
        "    \n",
        "  def __call__(self, model, val_loss):\n",
        "    if self.best_loss == None:\n",
        "      self.best_loss = val_loss\n",
        "      self.best_model = copy.deepcopy(model)\n",
        "    elif self.best_loss - val_loss > self.min_delta:\n",
        "      self.best_loss = val_loss\n",
        "      self.counter = 0\n",
        "      self.best_model.load_state_dict(model.state_dict())\n",
        "    elif self.best_loss - val_loss < self.min_delta:\n",
        "      self.counter += 1\n",
        "      if self.counter >= self.patience:\n",
        "        self.status = f\"Stopped on {self.counter}\"\n",
        "        if self.restore_best_weights:\n",
        "          model.load_state_dict(self.best_model.state_dict())\n",
        "        return True\n",
        "    self.status = f\"{self.counter}/{self.patience}\"\n",
        "    return False"
      ],
      "metadata": {
        "id": "IQ1ng25QhlJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_UCCRGkPuk1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the data set\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Generate dummies for job\n",
        "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
        "df.drop('job', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for area\n",
        "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
        "df.drop('area', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for product\n",
        "df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\")],axis=1)\n",
        "df.drop('product', axis=1, inplace=True)\n",
        "\n",
        "# Missing values for income\n",
        "med = df['income'].median()\n",
        "df['income'] = df['income'].fillna(med)\n",
        "\n",
        "# Standardize ranges\n",
        "df['income'] = zscore(df['income'])\n",
        "df['aspect'] = zscore(df['aspect'])\n",
        "df['save_rate'] = zscore(df['save_rate'])\n",
        "df['subscriptions'] = zscore(df['subscriptions'])\n",
        "\n",
        "# Convert to numpy - Classification\n",
        "x_columns = df.columns.drop('age').drop('id')\n",
        "x = df[x_columns].values\n",
        "y = df['age'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-iaytEOPuk2"
      },
      "source": [
        "Now that the feature vector is created a 5-fold cross-validation can be performed to generate out-of-sample predictions.  We will assume 500 epochs and not use early stopping.  Later we will see how we can estimate a more optimal epoch count."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yffwInTjPuk2",
        "outputId": "eb7d7167-c760-4092-d528-30ba9f8c221c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss 34.39945983886719:  94%|█████████▍| 94/100 [00:04<00:00, 67.04it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([400])) that is different to the input size (torch.Size([400, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss: 30.578550338745117, vloss: 43.894638, EStop:[0/5]: 100%|██████████| 100/100 [00:04<00:00, 22.60it/s]\n",
            "Epoch: 2, tloss: 9.249143600463867, vloss: 22.657480, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 119.57it/s]\n",
            "Epoch: 3, tloss: 14.337535858154297, vloss: 16.175705, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 103.78it/s]\n",
            "Epoch: 4, tloss: 18.48504638671875, vloss: 16.491512, EStop:[1/5]: 100%|██████████| 100/100 [00:01<00:00, 79.80it/s]\n",
            "Epoch: 5, tloss: 25.37423324584961, vloss: 19.750761, EStop:[2/5]: 100%|██████████| 100/100 [00:01<00:00, 73.26it/s]\n",
            "Epoch: 6, tloss: 12.55465030670166, vloss: 16.859362, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 116.70it/s]\n",
            "Epoch: 7, tloss: 16.12624168395996, vloss: 17.102427, EStop:[4/5]: 100%|██████████| 100/100 [00:00<00:00, 125.50it/s]\n",
            "Epoch: 8, tloss: 33.937992095947266, vloss: 17.794113, EStop:[Stopped on 5]: 100%|██████████| 100/100 [00:00<00:00, 128.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold score (RMSE): 4.177460670471191\n",
            "Fold #2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss 62.60527038574219:  92%|█████████▏| 92/100 [00:00<00:00, 124.53it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([400])) that is different to the input size (torch.Size([400, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss: 46.080265045166016, vloss: 41.330215, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 121.87it/s]\n",
            "Epoch: 2, tloss: 23.554439544677734, vloss: 19.077240, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 125.44it/s]\n",
            "Epoch: 3, tloss: 9.904412269592285, vloss: 17.828743, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 144.42it/s]\n",
            "Epoch: 4, tloss: 14.562386512756348, vloss: 19.205624, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 116.10it/s]\n",
            "Epoch: 5, tloss: 15.748347282409668, vloss: 20.499165, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 149.69it/s]\n",
            "Epoch: 6, tloss: 13.248491287231445, vloss: 16.023619, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 171.50it/s]\n",
            "Epoch: 7, tloss: 13.56807804107666, vloss: 17.985609, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 174.91it/s]\n",
            "Epoch: 8, tloss: 24.326189041137695, vloss: 16.131838, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 157.74it/s]\n",
            "Epoch: 9, tloss: 6.019631385803223, vloss: 16.478313, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 161.61it/s]\n",
            "Epoch: 10, tloss: 28.28997802734375, vloss: 15.680309, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 161.56it/s]\n",
            "Epoch: 11, tloss: 15.8753023147583, vloss: 22.736927, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 161.28it/s]\n",
            "Epoch: 12, tloss: 24.26561737060547, vloss: 15.910117, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 171.55it/s]\n",
            "Epoch: 13, tloss: 6.46457576751709, vloss: 20.075384, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 150.29it/s]\n",
            "Epoch: 14, tloss: 10.03924560546875, vloss: 16.497345, EStop:[4/5]: 100%|██████████| 100/100 [00:00<00:00, 141.06it/s]\n",
            "Epoch: 15, tloss: 9.472588539123535, vloss: 16.083647, EStop:[Stopped on 5]: 100%|██████████| 100/100 [00:00<00:00, 173.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold score (RMSE): 3.90688157081604\n",
            "Fold #3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss 26.349693298339844:  85%|████████▌ | 85/100 [00:00<00:00, 170.52it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([400])) that is different to the input size (torch.Size([400, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss: 50.78443145751953, vloss: 42.575474, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 166.35it/s]\n",
            "Epoch: 2, tloss: 23.228158950805664, vloss: 16.819767, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 156.12it/s]\n",
            "Epoch: 3, tloss: 35.030948638916016, vloss: 18.762680, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 168.18it/s]\n",
            "Epoch: 4, tloss: 16.667007446289062, vloss: 15.578781, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 165.31it/s]\n",
            "Epoch: 5, tloss: 25.617565155029297, vloss: 16.492470, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 166.26it/s]\n",
            "Epoch: 6, tloss: 7.281801223754883, vloss: 14.466459, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 172.73it/s]\n",
            "Epoch: 7, tloss: 15.833910942077637, vloss: 16.955782, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 162.36it/s]\n",
            "Epoch: 8, tloss: 15.108352661132812, vloss: 15.126785, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 149.11it/s]\n",
            "Epoch: 9, tloss: 20.686229705810547, vloss: 15.812305, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 151.24it/s]\n",
            "Epoch: 10, tloss: 13.1212158203125, vloss: 19.408604, EStop:[4/5]: 100%|██████████| 100/100 [00:00<00:00, 154.81it/s]\n",
            "Epoch: 11, tloss: 24.914215087890625, vloss: 16.174629, EStop:[Stopped on 5]: 100%|██████████| 100/100 [00:00<00:00, 151.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold score (RMSE): 3.9992218017578125\n",
            "Fold #4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss 52.286415100097656:  87%|████████▋ | 87/100 [00:00<00:00, 132.57it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([400])) that is different to the input size (torch.Size([400, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss: 124.17198181152344, vloss: 56.555309, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 136.00it/s]\n",
            "Epoch: 2, tloss: 20.612083435058594, vloss: 18.344934, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 149.57it/s]\n",
            "Epoch: 3, tloss: 14.890791893005371, vloss: 15.424962, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 165.52it/s]\n",
            "Epoch: 4, tloss: 8.32586669921875, vloss: 15.830782, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 163.84it/s]\n",
            "Epoch: 5, tloss: 14.84170913696289, vloss: 14.789660, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 156.47it/s]\n",
            "Epoch: 6, tloss: 7.293020725250244, vloss: 14.778517, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 153.11it/s]\n",
            "Epoch: 7, tloss: 13.877546310424805, vloss: 14.837282, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 162.85it/s]\n",
            "Epoch: 8, tloss: 12.859580993652344, vloss: 28.925959, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 154.23it/s]\n",
            "Epoch: 9, tloss: 15.454404830932617, vloss: 14.784056, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 154.99it/s]\n",
            "Epoch: 10, tloss: 9.753118515014648, vloss: 14.435871, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 166.58it/s]\n",
            "Epoch: 11, tloss: 17.641616821289062, vloss: 18.418537, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 166.69it/s]\n",
            "Epoch: 12, tloss: 10.3672513961792, vloss: 14.180185, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 154.41it/s]\n",
            "Epoch: 13, tloss: 8.9998140335083, vloss: 17.220379, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 162.65it/s]\n",
            "Epoch: 14, tloss: 15.092266082763672, vloss: 14.741219, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 158.19it/s]\n",
            "Epoch: 15, tloss: 25.542030334472656, vloss: 14.377803, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 165.72it/s]\n",
            "Epoch: 16, tloss: 64.78839111328125, vloss: 38.004807, EStop:[4/5]: 100%|██████████| 100/100 [00:00<00:00, 165.27it/s]\n",
            "Epoch: 17, tloss: 11.7532377243042, vloss: 14.128298, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 160.40it/s]\n",
            "Epoch: 18, tloss: 14.445182800292969, vloss: 13.981304, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 166.82it/s]\n",
            "Epoch: 19, tloss: 12.893657684326172, vloss: 15.041090, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 155.10it/s]\n",
            "Epoch: 20, tloss: 13.137258529663086, vloss: 15.043600, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 158.72it/s]\n",
            "Epoch: 21, tloss: 8.118425369262695, vloss: 14.297027, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 162.34it/s]\n",
            "Epoch: 22, tloss: 9.257301330566406, vloss: 14.571003, EStop:[4/5]: 100%|██████████| 100/100 [00:00<00:00, 158.32it/s]\n",
            "Epoch: 23, tloss: 26.280628204345703, vloss: 15.995957, EStop:[Stopped on 5]: 100%|██████████| 100/100 [00:00<00:00, 153.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold score (RMSE): 3.5507962703704834\n",
            "Fold #5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss 147.9426727294922:  86%|████████▌ | 86/100 [00:00<00:00, 166.07it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([400])) that is different to the input size (torch.Size([400, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss: 25.368885040283203, vloss: 47.316936, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 165.82it/s]\n",
            "Epoch: 2, tloss: 31.06095314025879, vloss: 15.951253, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 163.07it/s]\n",
            "Epoch: 3, tloss: 19.316743850708008, vloss: 15.081687, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 164.57it/s]\n",
            "Epoch: 4, tloss: 13.616600036621094, vloss: 15.750995, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 162.58it/s]\n",
            "Epoch: 5, tloss: 64.75232696533203, vloss: 13.487203, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 159.97it/s]\n",
            "Epoch: 6, tloss: 11.454826354980469, vloss: 13.751986, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 161.67it/s]\n",
            "Epoch: 7, tloss: 25.83644676208496, vloss: 15.916903, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 170.17it/s]\n",
            "Epoch: 8, tloss: 13.691373825073242, vloss: 14.814498, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 163.56it/s]\n",
            "Epoch: 9, tloss: 8.320444107055664, vloss: 16.589724, EStop:[4/5]: 100%|██████████| 100/100 [00:00<00:00, 155.46it/s]\n",
            "Epoch: 10, tloss: 7.7712836265563965, vloss: 12.941840, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 163.02it/s]\n",
            "Epoch: 11, tloss: 8.916894912719727, vloss: 16.711588, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 170.48it/s]\n",
            "Epoch: 12, tloss: 18.385311126708984, vloss: 13.848161, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 164.79it/s]\n",
            "Epoch: 13, tloss: 11.382552146911621, vloss: 12.955023, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 155.11it/s]\n",
            "Epoch: 14, tloss: 13.046331405639648, vloss: 12.797312, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 156.41it/s]\n",
            "Epoch: 15, tloss: 13.773503303527832, vloss: 22.619833, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 160.77it/s]\n",
            "Epoch: 16, tloss: 15.488056182861328, vloss: 14.559022, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 165.12it/s]\n",
            "Epoch: 17, tloss: 13.468666076660156, vloss: 13.134123, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 169.43it/s]\n",
            "Epoch: 18, tloss: 13.238396644592285, vloss: 13.000034, EStop:[4/5]: 100%|██████████| 100/100 [00:00<00:00, 164.16it/s]\n",
            "Epoch: 19, tloss: 14.84415340423584, vloss: 17.903774, EStop:[Stopped on 5]: 100%|██████████| 100/100 [00:00<00:00, 165.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold score (RMSE): 3.3854522705078125\n",
            "Final, out of sample score (RMSE): 3.815183162689209\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from sklearn import preprocessing\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "import tqdm\n",
        "import time\n",
        "\n",
        "EPOCHS=500\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Define the PyTorch Neural Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, in_count, out_count):\n",
        "        super(Net, self).__init__()\n",
        "        # We must define each of the layers.\n",
        "        self.fc1 = nn.Linear(in_count, 50)\n",
        "        self.fc2 = nn.Linear(50, 25)\n",
        "        self.fc3 = nn.Linear(25, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # In the forward pass, we must calculate all of the layers we \n",
        "        # previously defined.\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "# Cross-Validate\n",
        "kf = KFold(5, shuffle=True, random_state=42) # Use for KFold classification\n",
        "oos_y_list = []\n",
        "oos_pred_list = []\n",
        "\n",
        "fold = 0\n",
        "for train, test in kf.split(x):\n",
        "    fold+=1\n",
        "    print(f\"Fold #{fold}\")\n",
        "        \n",
        "    x_train = x[train]\n",
        "    y_train = y[train]\n",
        "    x_test = x[test]\n",
        "    y_test = y[test]\n",
        "\n",
        "    # Numpy to PyTorch\n",
        "    x_train = torch.Tensor(x_train).float()\n",
        "    y_train = torch.Tensor(y_train).float()\n",
        "\n",
        "    x_test = torch.Tensor(x_test).float().to(device)\n",
        "    y_test = torch.Tensor(y_test).float().to(device)\n",
        "\n",
        "    # Create datasets\n",
        "    dataset_train = TensorDataset(x_train, y_train)\n",
        "    dataloader_train = DataLoader(dataset_train,\\\n",
        "      batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    dataset_test = TensorDataset(x_test, y_test)\n",
        "    dataloader_test = DataLoader(dataset_test,\\\n",
        "      batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # Train the network\n",
        "    model = Net(x.shape[1],1).to(device)\n",
        "\n",
        "    # Define the loss function for regression\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    es = EarlyStopping()\n",
        "\n",
        "    epoch = 0\n",
        "    done = False\n",
        "    while epoch<1000 and not done:\n",
        "      epoch += 1\n",
        "      steps = list(enumerate(dataloader_train))\n",
        "      pbar = tqdm.tqdm(steps)\n",
        "      model.train()\n",
        "      for i, (x_batch, y_batch) in pbar:\n",
        "        y_batch_pred = model(x_batch.to(device))\n",
        "        loss = loss_fn(y_batch_pred, y_batch.to(device))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        loss, current = loss.item(), (i + 1)* len(x_batch)\n",
        "        if i == len(steps)-1:\n",
        "          model.eval()\n",
        "          pred = model(x_test)\n",
        "          vloss = loss_fn(pred, y_test)\n",
        "          if es(model,vloss): done = True\n",
        "          pbar.set_description(f\"Epoch: {epoch}, tloss: {loss}, vloss: {vloss:>7f}, EStop:[{es.status}]\")\n",
        "        else:\n",
        "          pbar.set_description(f\"Epoch: {epoch}, tloss {loss:}\")\n",
        "    \n",
        "    pred = model(x_test)\n",
        "    \n",
        "    oos_y_list.append(y_test.cpu().detach())\n",
        "    oos_pred_list.append(pred.cpu().detach())    \n",
        "\n",
        "    # Measure this fold's RMSE\n",
        "    score = np.sqrt(metrics.mean_squared_error(pred.cpu().detach(),y_test.cpu().detach()))\n",
        "    print(f\"Fold score (RMSE): {score}\")\n",
        "\n",
        "# Build the oos prediction list and calculate the error.\n",
        "oos_y = np.concatenate(oos_y_list)\n",
        "oos_pred = np.concatenate(oos_pred_list)\n",
        "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
        "print(f\"Final, out of sample score (RMSE): {score}\")    \n",
        "    \n",
        "# Write the cross-validated prediction\n",
        "oos_y = pd.DataFrame(oos_y)\n",
        "oos_pred = pd.DataFrame(oos_pred)\n",
        "oosDF = pd.concat( [df, oos_y, oos_pred],axis=1 )\n",
        "#oosDF.to_csv(filename_write,index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxTNAGA7Puk2"
      },
      "source": [
        "As you can see, the above code also reports the average number of epochs needed.  A common technique is to then train on the entire dataset for the average number of epochs required.\n",
        "\n",
        "## Classification with Stratified K-Fold Cross-Validation\n",
        "\n",
        "The following code trains and fits the **jh**-simple-dataset dataset with cross-validation to generate out-of-sample.  It also writes the out-of-sample (predictions on the test set) results.\n",
        "\n",
        "It is good to perform stratified k-fold cross-validation with classification data.  This technique ensures that the percentages of each class remain the same across all folds.  Use the **StratifiedKFold** object instead of the **KFold** object used in the regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5E9osqoPuk2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Read the data set\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Generate dummies for job\n",
        "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
        "df.drop('job', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for area\n",
        "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
        "df.drop('area', axis=1, inplace=True)\n",
        "\n",
        "# Missing values for income\n",
        "med = df['income'].median()\n",
        "df['income'] = df['income'].fillna(med)\n",
        "\n",
        "# Standardize ranges\n",
        "df['income'] = zscore(df['income'])\n",
        "df['aspect'] = zscore(df['aspect'])\n",
        "df['save_rate'] = zscore(df['save_rate'])\n",
        "df['age'] = zscore(df['age'])\n",
        "df['subscriptions'] = zscore(df['subscriptions'])\n",
        "\n",
        "# Convert to numpy - Classification\n",
        "x_columns = df.columns.drop('product').drop('id')\n",
        "x = df[x_columns].values\n",
        "dummies = pd.get_dummies(df['product']) # Classification\n",
        "products = dummies.columns\n",
        "y = dummies.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neqjbbOwPuk2"
      },
      "source": [
        "We will assume 500 epochs and not use early stopping.  Later we will see how we can estimate a more optimal epoch count."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from sklearn import preprocessing\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "import tqdm\n",
        "import time\n",
        "\n",
        "EPOCHS=500\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Define the PyTorch Neural Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, in_count, out_count):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_count, 50)\n",
        "        self.fc2 = nn.Linear(50, 25)\n",
        "        self.fc3 = nn.Linear(25, out_count)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.softmax(self.fc3(x))\n",
        "\n",
        "# Cross-Validate\n",
        "kf = KFold(5, shuffle=True, random_state=42) # Use for KFold classification\n",
        "oos_y_list = []\n",
        "oos_pred_list = []\n",
        "\n",
        "fold = 0\n",
        "for train, test in kf.split(x):\n",
        "    fold+=1\n",
        "    print(f\"Fold #{fold}\")\n",
        "        \n",
        "    x_train = x[train]\n",
        "    y_train = y[train]\n",
        "    x_test = x[test]\n",
        "    y_test = y[test]\n",
        "\n",
        "    # Numpy to PyTorch\n",
        "    x_train = torch.Tensor(x_train).float()\n",
        "    y_train = torch.Tensor(y_train).float()\n",
        "\n",
        "    x_test = torch.Tensor(x_test).float().to(device)\n",
        "    y_test = torch.Tensor(y_test).float().to(device)\n",
        "\n",
        "    # Create datasets\n",
        "    dataset_train = TensorDataset(x_train, y_train)\n",
        "    dataloader_train = DataLoader(dataset_train,\\\n",
        "      batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    dataset_test = TensorDataset(x_test, y_test)\n",
        "    dataloader_test = DataLoader(dataset_test,\\\n",
        "      batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # Train the network\n",
        "    model = Net(x.shape[1],len(products)).to(device)\n",
        "\n",
        "    # Define the loss function for classification\n",
        "    loss_fn = nn.CrossEntropyLoss()# cross entropy loss\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    es = EarlyStopping()\n",
        "\n",
        "    epoch = 0\n",
        "    done = False\n",
        "    while epoch<1000 and not done:\n",
        "      epoch += 1\n",
        "      steps = list(enumerate(dataloader_train))\n",
        "      pbar = tqdm.tqdm(steps)\n",
        "      model.train()\n",
        "      for i, (x_batch, y_batch) in pbar:\n",
        "        y_batch_pred = model(x_batch.to(device))\n",
        "        loss = loss_fn(y_batch_pred, y_batch.to(device))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        loss, current = loss.item(), (i + 1)* len(x_batch)\n",
        "        if i == len(steps)-1:\n",
        "          model.eval()\n",
        "          pred = model(x_test)\n",
        "          vloss = loss_fn(pred, y_test)\n",
        "          if es(model,vloss): done = True\n",
        "          pbar.set_description(f\"Epoch: {epoch}, tloss: {loss}, vloss: {vloss:>7f}, EStop:[{es.status}]\")\n",
        "        else:\n",
        "          pbar.set_description(f\"Epoch: {epoch}, tloss {loss:}\")\n",
        "    \n",
        "    pred = model(x_test)\n",
        "    \n",
        "    oos_y_list.append(y_test.cpu().detach())\n",
        "    oos_pred_list.append(pred.cpu().detach())    \n",
        "\n",
        "    # Measure this fold's RMSE\n",
        "    #score = np.sqrt(metrics.mean_squared_error(pred.cpu().detach(),y_test.cpu().detach()))\n",
        "    #print(f\"Fold score (RMSE): {score}\")\n",
        "\n",
        "    # Measure this fold's accuracy\n",
        "    y_compare = np.argmax(y_test.cpu().detach(),axis=1) # For accuracy calculation\n",
        "    pred = np.argmax(pred.cpu().detach(),axis=1) # For accuracy calculation\n",
        "    score = metrics.accuracy_score(y_compare, pred)\n",
        "    print(f\"Fold score (accuracy): {score}\")\n"
      ],
      "metadata": {
        "id": "ZERV0i8xVPP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96462fe-8527-4d1e-9e80-81d106eda423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 1, tloss: 1.6087956428527832, vloss: 1.670450, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 165.36it/s]\n",
            "Epoch: 2, tloss: 1.6654220819473267, vloss: 1.671296, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 166.64it/s]\n",
            "Epoch: 3, tloss: 1.563202977180481, vloss: 1.652720, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 169.47it/s]\n",
            "Epoch: 4, tloss: 1.727919340133667, vloss: 1.650997, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 165.07it/s]\n",
            "Epoch: 5, tloss: 1.6640689373016357, vloss: 1.670205, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 158.33it/s]\n",
            "Epoch: 6, tloss: 1.6031205654144287, vloss: 1.655255, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 163.95it/s]\n",
            "Epoch: 7, tloss: 1.5405099391937256, vloss: 1.655346, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 170.34it/s]\n",
            "Epoch: 8, tloss: 1.7903709411621094, vloss: 1.666811, EStop:[4/5]: 100%|██████████| 100/100 [00:00<00:00, 165.79it/s]\n",
            "Epoch: 9, tloss: 1.9779222011566162, vloss: 1.652718, EStop:[Stopped on 5]: 100%|██████████| 100/100 [00:00<00:00, 164.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold score (accuracy): 0.51\n",
            "Fold #2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 1, tloss: 1.6029226779937744, vloss: 1.705420, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 169.29it/s]\n",
            "Epoch: 2, tloss: 1.6029179096221924, vloss: 1.705420, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 170.14it/s]\n",
            "Epoch: 3, tloss: 1.4779222011566162, vloss: 1.705420, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 174.69it/s]\n",
            "Epoch: 4, tloss: 1.7902865409851074, vloss: 1.705407, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 164.60it/s]\n",
            "Epoch: 5, tloss: 1.7904220819473267, vloss: 1.705422, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 172.88it/s]\n",
            "Epoch: 6, tloss: 1.7904222011566162, vloss: 1.705422, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 168.53it/s]\n",
            "Epoch: 7, tloss: 1.6654222011566162, vloss: 1.705422, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 169.81it/s]\n",
            "Epoch: 8, tloss: 1.7279222011566162, vloss: 1.705422, EStop:[4/5]: 100%|██████████| 100/100 [00:00<00:00, 171.20it/s]\n",
            "Epoch: 9, tloss: 1.7904222011566162, vloss: 1.705422, EStop:[Stopped on 5]: 100%|██████████| 100/100 [00:00<00:00, 170.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold score (accuracy): 0.46\n",
            "Fold #3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 1, tloss: 1.718611240386963, vloss: 1.717940, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 164.68it/s]\n",
            "Epoch: 2, tloss: 1.4582247734069824, vloss: 1.473347, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 167.74it/s]\n",
            "Epoch: 3, tloss: 1.3773486614227295, vloss: 1.490890, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 172.32it/s]\n",
            "Epoch: 4, tloss: 1.3661129474639893, vloss: 1.477760, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 171.39it/s]\n",
            "Epoch: 5, tloss: 1.478950023651123, vloss: 1.488662, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 174.45it/s]\n",
            "Epoch: 6, tloss: 1.42991042137146, vloss: 1.473330, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 164.33it/s]\n",
            "Epoch: 7, tloss: 1.4827299118041992, vloss: 1.467703, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 164.59it/s]\n",
            "Epoch: 8, tloss: 1.4781827926635742, vloss: 1.457410, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 169.18it/s]\n",
            "Epoch: 9, tloss: 1.3880345821380615, vloss: 1.488907, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 161.99it/s]\n",
            "Epoch: 10, tloss: 1.531483769416809, vloss: 1.513516, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 161.31it/s]\n",
            "Epoch: 11, tloss: 1.2283519506454468, vloss: 1.457941, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 167.06it/s]\n",
            "Epoch: 12, tloss: 1.3549444675445557, vloss: 1.452927, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 173.07it/s]\n",
            "Epoch: 13, tloss: 1.4154762029647827, vloss: 1.481006, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 159.40it/s]\n",
            "Epoch: 14, tloss: 1.5405242443084717, vloss: 1.455969, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 167.85it/s]\n",
            "Epoch: 15, tloss: 1.5623838901519775, vloss: 1.473140, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 161.86it/s]\n",
            "Epoch: 16, tloss: 1.352881908416748, vloss: 1.473586, EStop:[4/5]: 100%|██████████| 100/100 [00:00<00:00, 159.82it/s]\n",
            "Epoch: 17, tloss: 1.605536937713623, vloss: 1.477000, EStop:[Stopped on 5]: 100%|██████████| 100/100 [00:00<00:00, 157.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold score (accuracy): 0.7125\n",
            "Fold #4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 1, tloss: 1.7097184658050537, vloss: 1.614560, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 164.01it/s]\n",
            "Epoch: 2, tloss: 1.4826369285583496, vloss: 1.554938, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 173.54it/s]\n",
            "Epoch: 3, tloss: 1.6032769680023193, vloss: 1.571010, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 167.88it/s]\n",
            "Epoch: 4, tloss: 1.7871029376983643, vloss: 1.530774, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 166.12it/s]\n",
            "Epoch: 5, tloss: 1.5062246322631836, vloss: 1.539827, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 170.83it/s]\n",
            "Epoch: 6, tloss: 1.616584300994873, vloss: 1.710253, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 168.25it/s]\n",
            "Epoch: 7, tloss: 1.4750868082046509, vloss: 1.528093, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 162.25it/s]\n",
            "Epoch: 8, tloss: 1.5480645895004272, vloss: 1.565197, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 152.87it/s]\n",
            "Epoch: 9, tloss: 1.708003044128418, vloss: 1.531778, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 160.26it/s]\n",
            "Epoch: 10, tloss: 1.4829965829849243, vloss: 1.611040, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 166.51it/s]\n",
            "Epoch: 11, tloss: 1.4782859086990356, vloss: 1.541615, EStop:[4/5]: 100%|██████████| 100/100 [00:00<00:00, 164.47it/s]\n",
            "Epoch: 12, tloss: 1.6029201745986938, vloss: 1.655953, EStop:[Stopped on 5]: 100%|██████████| 100/100 [00:00<00:00, 152.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold score (accuracy): 0.64\n",
            "Fold #5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 1, tloss: 1.731004238128662, vloss: 1.684747, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 167.78it/s]\n",
            "Epoch: 2, tloss: 1.657412052154541, vloss: 1.536799, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 171.53it/s]\n",
            "Epoch: 3, tloss: 1.7215187549591064, vloss: 1.510977, EStop:[0/5]: 100%|██████████| 100/100 [00:00<00:00, 165.47it/s]\n",
            "Epoch: 4, tloss: 1.606339454650879, vloss: 1.515504, EStop:[1/5]: 100%|██████████| 100/100 [00:00<00:00, 165.22it/s]\n",
            "Epoch: 5, tloss: 1.3746075630187988, vloss: 1.637032, EStop:[2/5]: 100%|██████████| 100/100 [00:00<00:00, 170.65it/s]\n",
            "Epoch: 6, tloss: 1.4720460176467896, vloss: 1.513013, EStop:[3/5]: 100%|██████████| 100/100 [00:00<00:00, 173.38it/s]\n",
            "Epoch: 7, tloss: 1.5504348278045654, vloss: 1.561378, EStop:[4/5]: 100%|██████████| 100/100 [00:00<00:00, 166.76it/s]\n",
            "Epoch: 8, tloss: 1.6036622524261475, vloss: 1.544061, EStop:[Stopped on 5]: 100%|██████████| 100/100 [00:00<00:00, 177.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold score (accuracy): 0.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the oos prediction list and calculate the error.\n",
        "oos_y = np.concatenate(oos_y_list)\n",
        "oos_pred = np.concatenate(oos_pred_list)\n",
        "oos_y = np.argmax(oos_y,axis=1)\n",
        "oos_pred = np.argmax(oos_pred,axis=1)\n",
        "score = metrics.accuracy_score(oos_pred,oos_y)\n",
        "print(f\"Final OOS score (accuracy): {score}\")\n",
        "\n",
        "# Write the cross-validated prediction\n",
        "oos_y_df = pd.DataFrame(oos_y)\n",
        "oos_pred_df = pd.DataFrame(oos_pred)\n",
        "oosDF = pd.concat( [df, oos_y_df, oos_pred_df],axis=1 )\n",
        "#oosDF.to_csv(filename_write,index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6aa4lYcM1E7",
        "outputId": "da5cfb47-e0b8-47df-91a6-ff9208ab9ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final OOS score (accuracy): 0.5965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Namils0RPuk3"
      },
      "source": [
        "## Training with both a Cross-Validation and a Holdout Set\n",
        "\n",
        "If you have a considerable amount of data, it is always valuable to set aside a holdout set before you cross-validate. This holdout set will be the final evaluation before using your model for its real-world use. Figure 5. HOLDOUT shows this division.\n",
        "\n",
        "**Figure 5. HOLDOUT: Cross-Validation and a Holdout Set**\n",
        "![Cross Validation and a Holdout Set](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_3_hold_train_val.png \"Cross-Validation and a Holdout Set\")\n",
        "\n",
        "The following program uses a holdout set and then still cross-validates.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3k3fiIc2Puk3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the data set\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Generate dummies for job\n",
        "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
        "df.drop('job', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for area\n",
        "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
        "df.drop('area', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for product\n",
        "df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\")],axis=1)\n",
        "df.drop('product', axis=1, inplace=True)\n",
        "\n",
        "# Missing values for income\n",
        "med = df['income'].median()\n",
        "df['income'] = df['income'].fillna(med)\n",
        "\n",
        "# Standardize ranges\n",
        "df['income'] = zscore(df['income'])\n",
        "df['aspect'] = zscore(df['aspect'])\n",
        "df['save_rate'] = zscore(df['save_rate'])\n",
        "df['subscriptions'] = zscore(df['subscriptions'])\n",
        "\n",
        "# Convert to numpy - Classification\n",
        "x_columns = df.columns.drop('age').drop('id')\n",
        "x = df[x_columns].values\n",
        "y = df['age'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSL7d64DPuk3"
      },
      "source": [
        "Now that the data has been preprocessed, we are ready to build the neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQnDC4YJPuk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff2f7ce-29e8-4939-c7c5-88e18f44a48b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/90 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss 49.82135772705078:  98%|█████████▊| 88/90 [00:00<00:00, 162.69it/s] /usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([360])) that is different to the input size (torch.Size([360, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss: 72.56485748291016, vloss: 54.645782, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 162.35it/s]\n",
            "Epoch: 2, tloss: 19.881534576416016, vloss: 19.900444, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 159.16it/s]\n",
            "Epoch: 3, tloss: 17.700916290283203, vloss: 18.652140, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 175.86it/s]\n",
            "Epoch: 4, tloss: 11.553352355957031, vloss: 16.144112, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 181.55it/s]\n",
            "Epoch: 5, tloss: 12.69009017944336, vloss: 15.238962, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 166.40it/s]\n",
            "Epoch: 6, tloss: 12.362306594848633, vloss: 18.409935, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 180.71it/s]\n",
            "Epoch: 7, tloss: 8.815723419189453, vloss: 16.545795, EStop:[2/5]: 100%|██████████| 90/90 [00:00<00:00, 177.16it/s]\n",
            "Epoch: 8, tloss: 16.19245147705078, vloss: 14.816410, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 176.94it/s]\n",
            "Epoch: 9, tloss: 42.04943084716797, vloss: 16.528973, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 164.66it/s]\n",
            "Epoch: 10, tloss: 9.867749214172363, vloss: 18.762512, EStop:[2/5]: 100%|██████████| 90/90 [00:00<00:00, 179.15it/s]\n",
            "Epoch: 11, tloss: 10.055387496948242, vloss: 14.306917, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 159.22it/s]\n",
            "Epoch: 12, tloss: 5.595019340515137, vloss: 14.797979, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 163.41it/s]\n",
            "Epoch: 13, tloss: 31.458839416503906, vloss: 23.022659, EStop:[2/5]: 100%|██████████| 90/90 [00:00<00:00, 156.51it/s]\n",
            "Epoch: 14, tloss: 25.248151779174805, vloss: 14.890406, EStop:[3/5]: 100%|██████████| 90/90 [00:00<00:00, 162.67it/s]\n",
            "Epoch: 15, tloss: 13.395263671875, vloss: 18.503834, EStop:[4/5]: 100%|██████████| 90/90 [00:00<00:00, 149.38it/s]\n",
            "Epoch: 16, tloss: 17.203144073486328, vloss: 15.688175, EStop:[Stopped on 5]: 100%|██████████| 90/90 [00:00<00:00, 165.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold score (RMSE): 3.838550090789795\n",
            "Fold #2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/90 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss 96.91532135009766:  90%|█████████ | 81/90 [00:00<00:00, 158.06it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([360])) that is different to the input size (torch.Size([360, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss: 65.76457977294922, vloss: 50.920387, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 154.95it/s]\n",
            "Epoch: 2, tloss: 13.398838996887207, vloss: 16.759438, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 157.08it/s]\n",
            "Epoch: 3, tloss: 7.2599968910217285, vloss: 16.348392, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 160.90it/s]\n",
            "Epoch: 4, tloss: 33.01200866699219, vloss: 15.119592, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 164.66it/s]\n",
            "Epoch: 5, tloss: 15.800431251525879, vloss: 14.899918, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 162.19it/s]\n",
            "Epoch: 6, tloss: 18.202293395996094, vloss: 18.668779, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 171.22it/s]\n",
            "Epoch: 7, tloss: 9.618451118469238, vloss: 24.711700, EStop:[2/5]: 100%|██████████| 90/90 [00:00<00:00, 172.80it/s]\n",
            "Epoch: 8, tloss: 5.976446151733398, vloss: 14.655143, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 163.61it/s]\n",
            "Epoch: 9, tloss: 13.475408554077148, vloss: 15.068759, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 170.81it/s]\n",
            "Epoch: 10, tloss: 8.327423095703125, vloss: 14.111535, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 169.46it/s]\n",
            "Epoch: 11, tloss: 9.87327766418457, vloss: 19.521667, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 174.06it/s]\n",
            "Epoch: 12, tloss: 27.923038482666016, vloss: 17.622232, EStop:[2/5]: 100%|██████████| 90/90 [00:00<00:00, 168.27it/s]\n",
            "Epoch: 13, tloss: 5.691408157348633, vloss: 16.508680, EStop:[3/5]: 100%|██████████| 90/90 [00:00<00:00, 176.15it/s]\n",
            "Epoch: 14, tloss: 29.535144805908203, vloss: 15.564190, EStop:[4/5]: 100%|██████████| 90/90 [00:00<00:00, 169.34it/s]\n",
            "Epoch: 15, tloss: 27.94898223876953, vloss: 17.443415, EStop:[Stopped on 5]: 100%|██████████| 90/90 [00:00<00:00, 167.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold score (RMSE): 3.5167007446289062\n",
            "Fold #3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/90 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss 83.65531921386719:  94%|█████████▍| 85/90 [00:00<00:00, 159.88it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([360])) that is different to the input size (torch.Size([360, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss: 79.90404510498047, vloss: 54.838440, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 157.64it/s]\n",
            "Epoch: 2, tloss: 36.34873580932617, vloss: 17.494644, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 156.38it/s]\n",
            "Epoch: 3, tloss: 28.1075496673584, vloss: 19.427069, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 175.10it/s]\n",
            "Epoch: 4, tloss: 17.659423828125, vloss: 15.360039, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 174.25it/s]\n",
            "Epoch: 5, tloss: 17.803409576416016, vloss: 15.534598, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 170.95it/s]\n",
            "Epoch: 6, tloss: 13.97917366027832, vloss: 14.996989, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 178.17it/s]\n",
            "Epoch: 7, tloss: 25.034334182739258, vloss: 16.119177, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 174.24it/s]\n",
            "Epoch: 8, tloss: 24.613719940185547, vloss: 20.997194, EStop:[2/5]: 100%|██████████| 90/90 [00:00<00:00, 165.50it/s]\n",
            "Epoch: 9, tloss: 16.141456604003906, vloss: 15.143198, EStop:[3/5]: 100%|██████████| 90/90 [00:00<00:00, 171.79it/s]\n",
            "Epoch: 10, tloss: 27.1475772857666, vloss: 16.913862, EStop:[4/5]: 100%|██████████| 90/90 [00:00<00:00, 172.37it/s]\n",
            "Epoch: 11, tloss: 16.72956085205078, vloss: 16.126108, EStop:[Stopped on 5]: 100%|██████████| 90/90 [00:00<00:00, 169.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold score (RMSE): 3.9091691970825195\n",
            "Fold #4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/90 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss 65.38216400146484:  94%|█████████▍| 85/90 [00:00<00:00, 163.43it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([360])) that is different to the input size (torch.Size([360, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss: 53.84135055541992, vloss: 48.789276, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 159.68it/s]\n",
            "Epoch: 2, tloss: 12.208961486816406, vloss: 24.114445, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 161.54it/s]\n",
            "Epoch: 3, tloss: 7.535606861114502, vloss: 22.149927, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 164.53it/s]\n",
            "Epoch: 4, tloss: 14.461817741394043, vloss: 15.741406, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 169.88it/s]\n",
            "Epoch: 5, tloss: 12.456652641296387, vloss: 16.828775, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 172.67it/s]\n",
            "Epoch: 6, tloss: 28.93013572692871, vloss: 21.270340, EStop:[2/5]: 100%|██████████| 90/90 [00:00<00:00, 175.13it/s]\n",
            "Epoch: 7, tloss: 11.464447975158691, vloss: 15.651596, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 168.37it/s]\n",
            "Epoch: 8, tloss: 15.525167465209961, vloss: 19.280731, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 161.36it/s]\n",
            "Epoch: 9, tloss: 9.210634231567383, vloss: 14.794357, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 170.50it/s]\n",
            "Epoch: 10, tloss: 24.677433013916016, vloss: 21.247183, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 167.31it/s]\n",
            "Epoch: 11, tloss: 9.838366508483887, vloss: 14.332788, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 169.06it/s]\n",
            "Epoch: 12, tloss: 10.778791427612305, vloss: 14.500366, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 174.35it/s]\n",
            "Epoch: 13, tloss: 27.809770584106445, vloss: 14.593118, EStop:[2/5]: 100%|██████████| 90/90 [00:00<00:00, 175.14it/s]\n",
            "Epoch: 14, tloss: 15.117850303649902, vloss: 15.699834, EStop:[3/5]: 100%|██████████| 90/90 [00:00<00:00, 172.08it/s]\n",
            "Epoch: 15, tloss: 22.227996826171875, vloss: 15.881686, EStop:[4/5]: 100%|██████████| 90/90 [00:00<00:00, 174.11it/s]\n",
            "Epoch: 16, tloss: 15.404528617858887, vloss: 14.102353, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 177.96it/s]\n",
            "Epoch: 17, tloss: 19.976646423339844, vloss: 20.936327, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 172.76it/s]\n",
            "Epoch: 18, tloss: 5.161701202392578, vloss: 15.986811, EStop:[2/5]: 100%|██████████| 90/90 [00:00<00:00, 172.48it/s]\n",
            "Epoch: 19, tloss: 9.707808494567871, vloss: 14.676033, EStop:[3/5]: 100%|██████████| 90/90 [00:00<00:00, 166.20it/s]\n",
            "Epoch: 20, tloss: 8.667880058288574, vloss: 14.267713, EStop:[4/5]: 100%|██████████| 90/90 [00:00<00:00, 167.05it/s]\n",
            "Epoch: 21, tloss: 12.079535484313965, vloss: 17.975967, EStop:[Stopped on 5]: 100%|██████████| 90/90 [00:00<00:00, 164.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold score (RMSE): 3.7630841732025146\n",
            "Fold #5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/90 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss 64.93468475341797:  91%|█████████ | 82/90 [00:00<00:00, 151.17it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([360])) that is different to the input size (torch.Size([360, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch: 1, tloss: 83.92796325683594, vloss: 69.805984, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 153.55it/s]\n",
            "Epoch: 2, tloss: 31.090370178222656, vloss: 24.205339, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 171.21it/s]\n",
            "Epoch: 3, tloss: 19.13016128540039, vloss: 22.080797, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 170.25it/s]\n",
            "Epoch: 4, tloss: 18.185937881469727, vloss: 18.302670, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 175.63it/s]\n",
            "Epoch: 5, tloss: 8.021072387695312, vloss: 16.906092, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 168.42it/s]\n",
            "Epoch: 6, tloss: 15.051443099975586, vloss: 17.442562, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 168.33it/s]\n",
            "Epoch: 7, tloss: 11.39267635345459, vloss: 18.741539, EStop:[2/5]: 100%|██████████| 90/90 [00:00<00:00, 169.44it/s]\n",
            "Epoch: 8, tloss: 15.929899215698242, vloss: 16.490429, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 169.39it/s]\n",
            "Epoch: 9, tloss: 12.120670318603516, vloss: 16.105709, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 163.23it/s]\n",
            "Epoch: 10, tloss: 23.56072235107422, vloss: 22.460707, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 177.79it/s]\n",
            "Epoch: 11, tloss: 9.056699752807617, vloss: 17.101913, EStop:[2/5]: 100%|██████████| 90/90 [00:00<00:00, 172.79it/s]\n",
            "Epoch: 12, tloss: 10.189562797546387, vloss: 15.983357, EStop:[0/5]: 100%|██████████| 90/90 [00:00<00:00, 175.82it/s]\n",
            "Epoch: 13, tloss: 12.457622528076172, vloss: 17.244799, EStop:[1/5]: 100%|██████████| 90/90 [00:00<00:00, 176.53it/s]\n",
            "Epoch: 14, tloss: 7.163581371307373, vloss: 21.000444, EStop:[2/5]: 100%|██████████| 90/90 [00:00<00:00, 166.65it/s]\n",
            "Epoch: 15, tloss: 13.432350158691406, vloss: 16.840559, EStop:[3/5]: 100%|██████████| 90/90 [00:00<00:00, 167.42it/s]\n",
            "Epoch: 16, tloss: 32.17474365234375, vloss: 18.256611, EStop:[4/5]: 100%|██████████| 90/90 [00:00<00:00, 153.91it/s]\n",
            "Epoch: 17, tloss: 6.905304908752441, vloss: 16.445580, EStop:[Stopped on 5]: 100%|██████████| 90/90 [00:00<00:00, 201.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold score (RMSE): 4.034495830535889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from sklearn import preprocessing\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "import tqdm\n",
        "import time\n",
        "\n",
        "# Keep a 10% holdout\n",
        "x_main, x_holdout, y_main, y_holdout = train_test_split(    \n",
        "    x, y, test_size=0.10) \n",
        "\n",
        "x_holdout = torch.Tensor(x_holdout).float().to(device)\n",
        "#y_holdout = torch.Tensor(y_holdout).float().to(device)\n",
        "\n",
        "EPOCHS=500\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Define the PyTorch Neural Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, in_count, out_count):\n",
        "        super(Net, self).__init__()\n",
        "        # We must define each of the layers.\n",
        "        self.fc1 = nn.Linear(in_count, 50)\n",
        "        self.fc2 = nn.Linear(50, 25)\n",
        "        self.fc3 = nn.Linear(25, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # In the forward pass, we must calculate all of the layers we \n",
        "        # previously defined.\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "# Cross-Validate\n",
        "kf = KFold(5, shuffle=True, random_state=42) # Use for KFold classification\n",
        "oos_y_list = []\n",
        "oos_pred_list = []\n",
        "\n",
        "fold = 0\n",
        "for train, test in kf.split(x_main):\n",
        "    fold+=1\n",
        "    print(f\"Fold #{fold}\")\n",
        "        \n",
        "    x_train = x_main[train]\n",
        "    y_train = y_main[train]\n",
        "    x_test = x_main[test]\n",
        "    y_test = y_main[test]\n",
        "\n",
        "    # Numpy to PyTorch\n",
        "    x_train = torch.Tensor(x_train).float()\n",
        "    y_train = torch.Tensor(y_train).float()\n",
        "\n",
        "    x_test = torch.Tensor(x_test).float().to(device)\n",
        "    y_test = torch.Tensor(y_test).float().to(device)\n",
        "\n",
        "    # Create datasets\n",
        "    dataset_train = TensorDataset(x_train, y_train)\n",
        "    dataloader_train = DataLoader(dataset_train,\\\n",
        "      batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    dataset_test = TensorDataset(x_test, y_test)\n",
        "    dataloader_test = DataLoader(dataset_test,\\\n",
        "      batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # Train the network\n",
        "    model = Net(x.shape[1],1).to(device)\n",
        "\n",
        "    # Define the loss function for regression\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    es = EarlyStopping()\n",
        "\n",
        "    epoch = 0\n",
        "    done = False\n",
        "    while epoch<1000 and not done:\n",
        "      epoch += 1\n",
        "      steps = list(enumerate(dataloader_train))\n",
        "      pbar = tqdm.tqdm(steps)\n",
        "      model.train()\n",
        "      for i, (x_batch, y_batch) in pbar:\n",
        "        y_batch_pred = model(x_batch.to(device))\n",
        "        loss = loss_fn(y_batch_pred, y_batch.to(device))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        loss, current = loss.item(), (i + 1)* len(x_batch)\n",
        "        if i == len(steps)-1:\n",
        "          model.eval()\n",
        "          pred = model(x_test)\n",
        "          vloss = loss_fn(pred, y_test)\n",
        "          if es(model,vloss): done = True\n",
        "          pbar.set_description(f\"Epoch: {epoch}, tloss: {loss}, vloss: {vloss:>7f}, EStop:[{es.status}]\")\n",
        "        else:\n",
        "          pbar.set_description(f\"Epoch: {epoch}, tloss {loss:}\")\n",
        "    \n",
        "    pred = model(x_test)\n",
        "    \n",
        "    oos_y_list.append(y_test.cpu().detach())\n",
        "    oos_pred_list.append(pred.cpu().detach())    \n",
        "\n",
        "    # Measure this fold's RMSE\n",
        "    score = np.sqrt(metrics.mean_squared_error(pred.cpu().detach(),y_test.cpu().detach()))\n",
        "    print(f\"Fold score (RMSE): {score}\")  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the oos prediction list and calculate the error.\n",
        "oos_y = np.concatenate(oos_y_list)\n",
        "oos_pred = np.concatenate(oos_pred_list)\n",
        "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
        "print(f\"Final, out of sample score (RMSE): {score}\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gDQgbkYtubh",
        "outputId": "b6d791cb-1ff0-4b70-e3cf-7f0b0d2c0f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final, out of sample score (RMSE): 3.816312551498413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FeJ58w1Puk4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46dda513-4315-4eb3-d5d8-f9ce6e84da18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Holdout score (RMSE): 3.519663184152827\n"
          ]
        }
      ],
      "source": [
        "# Write the cross-validated prediction (from the last neural network)\n",
        "holdout_pred = model(x_holdout).cpu().detach()\n",
        "\n",
        "score = np.sqrt(metrics.mean_squared_error(holdout_pred,y_holdout))\n",
        "print(f\"Holdout score (RMSE): {score}\") "
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.9 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "t81_558_class_05_2_kfold.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}